{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed = 0\n",
    "\n",
    "Probe = ['ipsweep', 'mscan', 'nmap', 'portsweep', 'saint', 'satan']\n",
    "\n",
    "DoS = ['apache2', 'back', 'land', 'mailbomb', 'neptune', 'pod', 'processtable', 'smurf', 'teardrop', 'udpstorm']\n",
    "\n",
    "U2R = ['buffer_overflow', 'httptunnel', 'loadmodule', 'perl', 'ps', 'rootkit', 'sqlattack', 'xterm']\n",
    "\n",
    "R2L = ['ftp_write', 'guess_passwd', 'imap', 'multihop', 'named', 'phf', 'sendmail', 'snmpgetattack', 'snmpguess',\n",
    "       'spy', 'warezclient', 'warezmaster', 'worm', 'xlock', 'xsnoop']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data and assign feature name to each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = []\n",
    "with open('kddcup.names') as f:\n",
    "    next(f)\n",
    "    for line in f:\n",
    "        feature = line.split(':')[0]\n",
    "        columns.append(feature)\n",
    "columns.append('label')\n",
    "\n",
    "train_data = pd.read_csv('../data/kddcup.data', header=None)\n",
    "train_data.columns = columns\n",
    "train_data['label'] = train_data['label'].apply(lambda x: x.replace('.', ''))\n",
    "\n",
    "test_data = pd.read_csv('../data/corrected', header=None)\n",
    "test_data.columns = columns\n",
    "test_data['label'] = test_data['label'].apply(lambda x: x.replace('.', ''))\n",
    "\n",
    "boundary = train_data.shape[0]\n",
    "whole_data = pd.concat([train_data, test_data], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_type = []\n",
    "#with open('kddcup.names') as f:\n",
    "#    next(f)\n",
    "#    for line in f:\n",
    "#        feature = line.split(': ')[1]\n",
    "#        data_type.append(feature[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data = whole_data.iloc[:boundary]\n",
    "#idx_symb = []\n",
    "#idx_cont = []\n",
    "#for idx, data_type in enumerate(data_type):\n",
    "#    if data_type == 'symbolic':\n",
    "#        idx_symb.append(idx)\n",
    "#    else:\n",
    "#        idx_cont.append(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['protocol_type', 'service', 'flag', 'land', 'logged_in', 'is_host_login', 'is_guest_login']\n",
    "whole_data_categorical = whole_data[categorical].copy()\n",
    "whole_data.drop(columns=categorical, inplace=True)\n",
    "whole_data_categorical_T = pd.get_dummies(whole_data_categorical)\n",
    "whole_data = pd.concat([whole_data_categorical_T, whole_data], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = whole_data.iloc[:boundary]\n",
    "test_data = whole_data.iloc[boundary:]\n",
    "\n",
    "X_train, y_train = train_data.drop(columns='label'), train_data['label']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, stratify=y_train, test_size=0.2, random_state=seed)\n",
    "X_test, y_test = test_data.drop(columns='label'), test_data['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category wise Outlier Detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to store outlier indices\n",
    "instances_as_outliers = [] \n",
    "\n",
    "# Threshold to select which label data to clean\n",
    "process_thresh = 1\n",
    "\n",
    "labels = train_data['label'].unique()\n",
    "for label in labels:\n",
    "    label_data = train_data.loc[train_data['label'] == label]\n",
    "    if label_data.shape[0] > process_thresh:\n",
    "        label_data = label_data.drop(columns='label')\n",
    "        mean = label_data.describe().loc['mean']\n",
    "        std = label_data.describe().loc['std']\n",
    "        \n",
    "        # Begin to filter outlier\n",
    "        for column in label_data:\n",
    "            feature_value = label_data[column].values\n",
    "            upper_bound = mean[column] + 3*std[column]\n",
    "            instances_as_outliers.append(label_data[feature_value>upper_bound].index)\n",
    "\n",
    "# Clean the repeated indices\n",
    "outlier_idx = []\n",
    "for idx_set in instances_as_outliers:\n",
    "    for idx in idx_set:\n",
    "        outlier_idx.append(idx)       \n",
    "outlier_idx = list(set(outlier_idx)) \n",
    "\n",
    "train_data_clean = train_data.drop(index=outlier_idx, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label distribution in Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normal             439586\n",
       "neptune             74634\n",
       "satan                1805\n",
       "smurf                1778\n",
       "portsweep            1658\n",
       "ipsweep               975\n",
       "nmap                  289\n",
       "back                  284\n",
       "warezclient           167\n",
       "teardrop              114\n",
       "pod                    39\n",
       "guess_passwd            8\n",
       "buffer_overflow         7\n",
       "land                    4\n",
       "imap                    3\n",
       "warezmaster             3\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers = train_data.iloc[list(outlier_idx),:]\n",
    "outliers['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label distribution in Origninal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smurf              2807886\n",
       "neptune            1072017\n",
       "normal              972781\n",
       "satan                15892\n",
       "ipsweep              12481\n",
       "portsweep            10413\n",
       "nmap                  2316\n",
       "back                  2203\n",
       "warezclient           1020\n",
       "teardrop               979\n",
       "pod                    264\n",
       "guess_passwd            53\n",
       "buffer_overflow         30\n",
       "land                    21\n",
       "warezmaster             20\n",
       "imap                    12\n",
       "rootkit                 10\n",
       "loadmodule               9\n",
       "ftp_write                8\n",
       "multihop                 7\n",
       "phf                      4\n",
       "perl                     3\n",
       "spy                      2\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert specific attack types to four general attack types in y_valid and y_test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attack in Probe:\n",
    "    y_valid = y_valid.replace(attack, 'Probe')\n",
    "    y_test = y_test.replace(attack, 'Probe')\n",
    "    \n",
    "for attack in DoS:\n",
    "    y_valid = y_valid.replace(attack, 'DoS')\n",
    "    y_test = y_test.replace(attack, 'DoS')\n",
    "    \n",
    "for attack in R2L:\n",
    "    y_valid = y_valid.replace(attack, 'R2L')\n",
    "    y_test = y_test.replace(attack, 'R2L')\n",
    "    \n",
    "for attack in U2R:\n",
    "    y_valid = y_valid.replace(attack, 'U2R')\n",
    "    y_test = y_test.replace(attack, 'U2R')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store preprocessed data for later usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_pickle(\"X_train.pkl\")\n",
    "y_train.to_pickle(\"y_train.pkl\")\n",
    "\n",
    "X_valid.to_pickle(\"X_valid.pkl\")\n",
    "y_valid.to_pickle(\"y_valid.pkl\")\n",
    "\n",
    "X_test.to_pickle(\"X_test.pkl\")\n",
    "y_test.to_pickle(\"y_test.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
